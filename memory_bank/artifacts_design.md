ðŸŽ¨ðŸŽ¨ðŸŽ¨ ENTERING CREATIVE PHASE: ARCHITECTURE

Component: Artifact domain model (generated by LLMs, consumed by backend and frontend)

Requirements & Constraints
- Must be generated via LLM structured output and validated
- Must be serializable, versionable, and stable across packages
- Must be easy to render in the frontend (Streamlit)
- Types identified: user_choice, follow_up_question, notes
- id MUST be generated by the backend (UUID); LLM must NOT emit it
- type MUST be assigned by the backend based on context; LLM must NOT emit it
- Discriminator remains a unique string literal bound to the domain class (backend-only)
- Keep max 4 user_choice artifacts in clarify flows
- Avoid frontend coupling to ai_engine internals; prefer shared core

Options
1) Place Pydantic models in core/models as discriminated union (Domain) + lightweight Draft input models
   - Pros: clear separation of concerns (LLM vs domain); strong typing; single source of truth; easy validation; JSON schema
   - Cons: two model layers to maintain (Draft and Domain)

2) Define JSON/TypedDict contracts in core/types; ai_engine keeps Pydantic wrappers
   - Pros: minimal runtime coupling; flexible for non-Python clients
   - Cons: duplication (contract vs model); weaker validation where wrappers arenâ€™t used

3) Keep in ai_engine/base and re-export to frontend
   - Pros: minimal change now
   - Cons: inverted dependency and not domain-centric; harder reuse

Recommended Approach
- Option 1 with two layers:
  - Draft models: inputs produced by LLM (no id, no type)
  - Domain models: backend-constructed artifacts with `id` and `type` populated, validated, and versioned
- Place both Draft and Domain models in core/models/artifacts.py
- For clarify flow, Draft -> Domain mapping will assign `type = "user_choice"` and generate UUIDs

Proposed Schema (reference)
```python
from __future__ import annotations
from typing import Annotated, Literal, Union, Any
from uuid import uuid4
from pydantic import BaseModel, Field

# ---------- Draft models (LLM output) ----------
# LLM MUST NOT emit id or type

class UserChoiceArtifactDraft(BaseModel):
    title: str
    description: str
    action_data: dict[str, Any] | None = None

class FollowUpQuestionArtifactDraft(BaseModel):
    question: str
    suggestions: list[str] | None = None

class NotesArtifactDraft(BaseModel):
    content: str

# ---------- Domain models (backend output) ----------
# Backend assigns id and type

class UserChoiceArtifact(BaseModel):
    type: Literal["user_choice"] = "user_choice"
    id: str = Field(default_factory=lambda: str(uuid4()), description="UUID v4")
    title: str
    description: str
    action_data: dict[str, Any] | None = None

class FollowUpQuestionArtifact(BaseModel):
    type: Literal["follow_up_question"] = "follow_up_question"
    id: str = Field(default_factory=lambda: str(uuid4()))
    question: str
    suggestions: list[str] | None = None

class NotesArtifact(BaseModel):
    type: Literal["notes"] = "notes"
    id: str = Field(default_factory=lambda: str(uuid4()))
    content: str

Artifact = Annotated[
    Union[UserChoiceArtifact, FollowUpQuestionArtifact, NotesArtifact],
    Field(discriminator="type"),
]

# ---------- Mapping helpers ----------

def user_choice_from_drafts(drafts: list[UserChoiceArtifactDraft]) -> list[UserChoiceArtifact]:
    return [UserChoiceArtifact(title=d.title, description=d.description, action_data=d.action_data) for d in drafts]
```

Placement & Package Boundaries
- File: packages/core/src/core/models/artifacts.py (contains both Draft and Domain models + mapping helpers)
- Re-export in packages/core/src/core/models/__init__.py
- Update ai_engine clarify state to accept Drafts from the model and convert to Domain before updating state/output
- Frontend consumes Domain artifacts only (unchanged fields: `.id/.title/.description`)

LLM Contract & Prompting
- LLM MUST NOT include `id` or `type` anywhere
- Clarify flow returns `artifacts` as an array of UserChoiceArtifactDraft (title, description, optional action_data)
- Example output snippet for clarify step:
```json
{
  "need_clarification": true,
  "question": "Which environment should I analyze?",
  "verification": "",
  "artifacts": [
    {"title": "Production", "description": "Live production environment"},
    {"title": "Staging", "description": "Pre-production environment"}
  ]
}
```

Validation & Constraints
- Enforce max 4 UserChoiceArtifact in clarify state after Draft->Domain conversion
- Normalize IDs to lowercase strings (if needed) at Domain level
- Keep `type` values stable; they are part of the backend API surface

Migration Plan
- Create core/models/artifacts.py with Draft and Domain models
- Replace current ai_engine `ArtifactType`/`_type` and `ClarificationArtifact` with imports from core
- Introduce `ClarifyWithUserDraft` (artifacts: list[UserChoiceArtifactDraft]) for LLM structured output
- In clarify graph node, convert Drafts to Domain via `user_choice_from_drafts()` before updating state/messages
- Update prompts to remove `id` and `type` from examples and instructions
- Verify frontend continues to work (consumes Domain artifacts only)

Verification Checkpoint
- Shared models compile in core
- Clarify graph returns Domain `UserChoiceArtifact` list with auto IDs and backend-assigned type
- Frontend renders and selection flows work
- Prompt examples are free of `id` and `type`

ðŸŽ¨ðŸŽ¨ðŸŽ¨ EXITING CREATIVE PHASE
